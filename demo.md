###统计学习符号
X：输入空间/特征空间
Y：输出空间
*X*：输入变量
*Y*：输出变量
x：输入变量的值
y：输出变量的值
$x_i=(x^{(1)},x^{(2)},...,x^{(n)})$：第i个输入实例x的特征向量，n是特征的个数
T=$\{(x_1,y_1),(x_2,y_2),...(x_N,y_N)\}$：训练集
P：概率
F：假设空间
$f \in{F}$：包含于假设空间F的模型f
$w=(w_1,w_2,...,w_n)$：权向量

##统计学习
统计学习包括监督学习、非监督学习、半监督学习和强化学习。
监督学习是学习一个模型，使得该模型对任意给定的输入能很好的预测输出。

##监督学习
###输入空间、特征空间和输出空间
    输入空间（X）：输入的所有可能的取值的空间。
    输出空间（Y）：输出的所有可能的取值的空间。
    特征空间（X）：每个输入由若干个特征表示，他们合起来叫做特征向量。特征向量组成的空间叫特征空间。特征空间在某些时候就是输入空间。
    训练集（T）：监督学习从训练数据集中学习模型，对测试数据进行预测。训练数据又输入数据和输出数据构成。
    样本/样本点：训练集中的输入与输出对。
    回归问题、分类问题和标注问题：输入变量与输出变量既可以是连续的也可以是离散的。输入和输出变量都是连续的预测问题成为回归问题；输出为有限个离散数据的预测问题称为分类问题；输入与输出都是离散的预测称为标注问题。（我想画3幅图说明，留着位置啊。）

###联合概率分布
随机变量$X$和$Y$遵循联合概率分布$P(X,Y)$。这个是统计学习中的一个基础假设。
###假设空间
输入到输出的映射是一个模型。输入空间到输出空间的所有映射/模型组成了一个空间，这个空间称为假设空间。假设空间包含所有的模型。监督学习的作用是在假设空间中搜索到最优的模型。


##1.3 统计学习三要素
统计学习三要素：模型 策略 算法
###1.3.1 模型
在监督学习过程中，模型就是所要学习的条件概率分布或决策函数。模型的假设空间包含所有的可能的条件概率分布或决策函数。假设空间中的模型一般有无穷多个。
假设空间用符号${F}$表示。决策函数的集合$${F}=\{f|Y=f(X)\}\\ 或 \ \ F=\{f|Y=f_\theta(X),\theta\in{R^n}\}$$ 式中$\theta$是属于n维欧氏空间$R^n$，称为参数空间。
假设空间也可以定义为条件概率的集合$$F=\{f|P(Y|X)\}\\ 或 \ \ F=\{f|P_\theta(Y|X),\theta\in{R^n}\}$$其中，X和Y分别是输入空间和输出空间的上的随机变量，$\theta$是属于n维欧氏空间$R^n$。
###1.3.2 策略
1. 损失函数
0-1损失函数：
$$L\left(Y,f(X)\right)=\begin{cases}1,&Y\neq{f(X)}\\0,&Y=f(X)\end{cases}$$
平方损失函数：
$$L\left(Y,f(X)\right)=\left(Y-f(X)\right)^2$$
绝对值损失函数：
$$L\left(Y,f(X)\right)=|Y-f(X)|$$
对数损失函数：
$$L\left(Y,f(X)\right)=-logP(Y|X)$$
损失函数值越小，模型越好。损失函数的期望是
$$R_{exp}(f)=E_p[L(Y,f(X)]=\int_{{X}\times{Y}}L(y,f(x))P(x,y)\rm{d}x\rm{d}y$$
2. 风险函数

###1.3.3 算法

##模型评估与模型选择
###训练误差与测试误差
对于模型$Y=f(X)$，训练误差是模型关于训练数据集的平均损失。由于训练数据是已知的，所以模型的训练误差可以求出。
对于模型$Y=f(X)$，测试误差是模型关于测试数据集的平均损失。模型的测试误差可以基于给出的测试数据集求出。
二者的公式：
$$R_{emp}(f)=\frac{1}N\sum_{i=1}^NL(y_i,f(x_i))$$
$$e_{test}(f)=\frac{1}{N'}\sum_{i=1}^{N'}L(y_i,f(x_i))$$
注：其中L是损失的意思，损失函数。常用的损失函数是损失的平方的1/2。

只要了解二者的关系就行了。随着模型的复杂度增加，训练误差逐渐减小趋近于0，测试误差先减小后增加。

###过拟合与模型选择
[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-MxkYV8td-1569726506494)(http://img.blog.csdn.net/20170308134220981?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2VpeGluXzM3NzIyMDI0/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)]

##正则化与交叉验证
##泛化能力
###泛化误差
###泛化误差上界
###生成模型与判别模型
理解了以后再写
###分类问题
###标注问题
###回归问题

